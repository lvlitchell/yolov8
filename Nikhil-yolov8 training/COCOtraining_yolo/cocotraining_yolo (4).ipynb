{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e1Vifbb1U1LQ",
    "outputId": "0c726b4e-bfde-409a-ba26-1462477e05a4"
   },
   "outputs": [],
   "source": [
    "#Mounting drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n",
      "11.7\n",
      "True\n",
      "5502926848\n",
      "5263157760\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.set_device(0)\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "# Print memory reserved and allocated\n",
    "print(torch.cuda.memory_reserved())\n",
    "print(torch.cuda.memory_allocated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-5zcco5_iRav",
    "outputId": "da9be62e-0b23-4762-e257-324f39e63d45",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib>=3.3.0 in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (from -r /home/nikhil/Documents/inseer_ML_Project/yolov8/requirements.txt (line 5)) (3.6.2)\n",
      "Requirement already satisfied: numpy>=1.22.2 in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (from -r /home/nikhil/Documents/inseer_ML_Project/yolov8/requirements.txt (line 6)) (1.24.1)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (from -r /home/nikhil/Documents/inseer_ML_Project/yolov8/requirements.txt (line 7)) (4.6.0)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (from -r /home/nikhil/Documents/inseer_ML_Project/yolov8/requirements.txt (line 8)) (9.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (from -r /home/nikhil/Documents/inseer_ML_Project/yolov8/requirements.txt (line 9)) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (from -r /home/nikhil/Documents/inseer_ML_Project/yolov8/requirements.txt (line 10)) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (from -r /home/nikhil/Documents/inseer_ML_Project/yolov8/requirements.txt (line 11)) (1.10.0)\n",
      "Requirement already satisfied: torch>=1.8.0 in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (from -r /home/nikhil/Documents/inseer_ML_Project/yolov8/requirements.txt (line 12)) (1.13.1)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (from -r /home/nikhil/Documents/inseer_ML_Project/yolov8/requirements.txt (line 13)) (0.14.1)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (from -r /home/nikhil/Documents/inseer_ML_Project/yolov8/requirements.txt (line 14)) (4.64.1)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (from -r /home/nikhil/Documents/inseer_ML_Project/yolov8/requirements.txt (line 23)) (2.1.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (from -r /home/nikhil/Documents/inseer_ML_Project/yolov8/requirements.txt (line 24)) (0.13.0)\n",
      "Requirement already satisfied: psutil in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (from -r /home/nikhil/Documents/inseer_ML_Project/yolov8/requirements.txt (line 39)) (5.9.6)\n",
      "Requirement already satisfied: py-cpuinfo in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (from -r /home/nikhil/Documents/inseer_ML_Project/yolov8/requirements.txt (line 40)) (9.0.0)\n",
      "Requirement already satisfied: thop>=0.1.1 in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (from -r /home/nikhil/Documents/inseer_ML_Project/yolov8/requirements.txt (line 41)) (0.1.1.post2209072238)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (from matplotlib>=3.3.0->-r /home/nikhil/Documents/inseer_ML_Project/yolov8/requirements.txt (line 5)) (23.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (from matplotlib>=3.3.0->-r /home/nikhil/Documents/inseer_ML_Project/yolov8/requirements.txt (line 5)) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (from matplotlib>=3.3.0->-r /home/nikhil/Documents/inseer_ML_Project/yolov8/requirements.txt (line 5)) (3.1.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (from matplotlib>=3.3.0->-r /home/nikhil/Documents/inseer_ML_Project/yolov8/requirements.txt (line 5)) (1.2.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (from matplotlib>=3.3.0->-r /home/nikhil/Documents/inseer_ML_Project/yolov8/requirements.txt (line 5)) (4.44.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (from matplotlib>=3.3.0->-r /home/nikhil/Documents/inseer_ML_Project/yolov8/requirements.txt (line 5)) (0.12.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (from matplotlib>=3.3.0->-r /home/nikhil/Documents/inseer_ML_Project/yolov8/requirements.txt (line 5)) (2.8.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (from requests>=2.23.0->-r /home/nikhil/Documents/inseer_ML_Project/yolov8/requirements.txt (line 10)) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (from requests>=2.23.0->-r /home/nikhil/Documents/inseer_ML_Project/yolov8/requirements.txt (line 10)) (2023.7.22)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (from requests>=2.23.0->-r /home/nikhil/Documents/inseer_ML_Project/yolov8/requirements.txt (line 10)) (2.0.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (from requests>=2.23.0->-r /home/nikhil/Documents/inseer_ML_Project/yolov8/requirements.txt (line 10)) (3.4)\n",
      "Requirement already satisfied: typing_extensions in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (from torch>=1.8.0->-r /home/nikhil/Documents/inseer_ML_Project/yolov8/requirements.txt (line 12)) (4.8.0)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (from pandas>=1.1.4->-r /home/nikhil/Documents/inseer_ML_Project/yolov8/requirements.txt (line 23)) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (from pandas>=1.1.4->-r /home/nikhil/Documents/inseer_ML_Project/yolov8/requirements.txt (line 23)) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->-r /home/nikhil/Documents/inseer_ML_Project/yolov8/requirements.txt (line 5)) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r ~/Documents/inseer_ML_Project/yolov8/requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "41AbvT1li-8v",
    "outputId": "5552c0fd-1e43-4bd6-cbfb-51cdd3a7e0ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (8.0.208)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (from ultralytics) (4.6.0)\n",
      "Requirement already satisfied: requests>=2.23.0 in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (from ultralytics) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (from ultralytics) (4.64.1)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (from ultralytics) (3.6.2)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (from ultralytics) (0.14.1)\n",
      "Requirement already satisfied: thop>=0.1.1 in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (from ultralytics) (0.1.1.post2209072238)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (from ultralytics) (1.10.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (from ultralytics) (1.13.1)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (from ultralytics) (2.1.3)\n",
      "Requirement already satisfied: psutil in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (from ultralytics) (5.9.6)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (from ultralytics) (0.13.0)\n",
      "Requirement already satisfied: numpy>=1.22.2 in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (from ultralytics) (1.24.1)\n",
      "Requirement already satisfied: py-cpuinfo in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (from ultralytics) (9.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (4.44.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (from requests>=2.23.0->ultralytics) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
      "Requirement already satisfied: typing_extensions in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (4.8.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ultralytics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "aIEdagfQhAmf"
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from types import SimpleNamespace\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from zipfile import ZipFile\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m70.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.17.3 in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (from scikit-learn) (1.24.1)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /home/nikhil/anaconda3/envs/yolov8/lib/python3.9/site-packages (from scikit-learn) (1.10.0)\n",
      "Collecting joblib>=1.1.1\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.2/302.2 kB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.3.2 scikit-learn-1.3.2 threadpoolctl-3.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "yeYS-w__tBcz"
   },
   "outputs": [],
   "source": [
    "zip_file_path = '/content/drive/Shareddrives/Nikhil shared drive/COCO-Hand.zip'\n",
    "extraction_path = '/content/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qR5m-mQwtZ6g",
    "outputId": "3b5a6f29-e8f8-4583-ec82-991105f56628"
   },
   "outputs": [],
   "source": [
    "# Unzip the file\n",
    "with ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extraction_path)\n",
    "\n",
    "print(\"Unzipped successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CwAVInW_eXRI"
   },
   "outputs": [],
   "source": [
    "#Splitting the dataset into train,test and val sets\n",
    "def split_images(images_dir, output_dir):\n",
    "    \"\"\"\n",
    "    Splits images into train, val, and test sets and move them to respective folders.\n",
    "    \"\"\"\n",
    "\n",
    "    # List all image filenames\n",
    "    images = [f for f in os.listdir(images_dir) if f.endswith('.jpg')]\n",
    "\n",
    "    # Split the filenames into train, val, and test sets\n",
    "    train_images, temp_images = train_test_split(images, test_size=0.2, random_state=42)\n",
    "    val_images, test_images = train_test_split(temp_images, test_size=0.5, random_state=42)\n",
    "\n",
    "    # Dictionaries to map split name to filenames\n",
    "    splits = {\n",
    "        'train': train_images,\n",
    "        'val': val_images,\n",
    "        'test': test_images\n",
    "    }\n",
    "\n",
    "    # Create directories for each split and move images to them\n",
    "    for split, split_images in splits.items():\n",
    "        split_dir = Path(output_dir) / split / 'images'\n",
    "        split_dir.mkdir(parents=True, exist_ok=True)\n",
    "        for img in split_images:\n",
    "            shutil.move(images_dir / img, split_dir / img)\n",
    "\n",
    "    return splits\n",
    "\n",
    "# Test the function\n",
    "images_dir = Path(os.path.expanduser(\"~/Documents/Datasets/COCO dataset/COCO-Hand/COCO-Hand-Big/COCO-Hand-Big_Images\"))\n",
    "output_dir = Path(os.path.expanduser(\"~/Documents/Datasets/COCO dataset/COCO-Hand-splitdata\"))\n",
    "\n",
    "# Call the function to split images\n",
    "splits = split_images(images_dir, output_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pRgbn89meXTu",
    "outputId": "a71f7585-61db-48a8-8eb8-e7e7fe4c8c94"
   },
   "outputs": [],
   "source": [
    "def load_annotations_from_file(annotation_file_path):\n",
    "    \"\"\"\n",
    "    Load annotations from the specified file.\n",
    "    \"\"\"\n",
    "    with open(annotation_file_path, 'r') as file:\n",
    "        annotations = [line.strip().split() for line in file.readlines()]\n",
    "    return annotations\n",
    "\n",
    "annotations = load_annotations_from_file(Path(os.path.expanduser(\"~/Documents/Datasets/COCO dataset/COCO-Hand/COCO-Hand-Big/COCO-Hand-Big_annotations.txt\")))\n",
    "print(f\"Total annotations loaded: {len(annotations)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "NuuevuH6eXXI"
   },
   "outputs": [],
   "source": [
    "# Define paths for each split\n",
    "train_images_path = Path(os.path.expanduser(\"~/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images\"))\n",
    "val_images_path = Path(os.path.expanduser(\"~/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/val/images\"))\n",
    "test_images_path = Path(os.path.expanduser(\"~/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/test/images\"))\n",
    "\n",
    "train_labels_path = Path(os.path.expanduser(\"~/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/labels\"))\n",
    "val_labels_path = Path(os.path.expanduser(\"~/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/val/labels\"))\n",
    "test_labels_path = Path(os.path.expanduser(\"~/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/test/labels\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p57wH-qQeXk3",
    "outputId": "b34c9c3a-7611-4d3a-e1da-8ade463e9ba7"
   },
   "outputs": [],
   "source": [
    "#path for the annotations file\n",
    "annotations_file_path =Path(os.path.expanduser(\"~/Documents/Datasets/COCO dataset/COCO-Hand/COCO-Hand-Big/COCO-Hand-Big_annotations.txt\"))\n",
    "\n",
    "\n",
    "\n",
    "# Load annotations from the provided file\n",
    "with open(annotations_file_path, 'r') as file:\n",
    "    annotations_data = [line.strip() for line in file.readlines()]\n",
    "\n",
    "\n",
    "# Define paths for each set\n",
    "train_images_path = Path(os.path.expanduser(\"~/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images\"))\n",
    "val_images_path = Path(os.path.expanduser(\"~/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/val/images\"))\n",
    "test_images_path = Path(os.path.expanduser(\"~/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/test/images\"))\n",
    "\n",
    "\n",
    "# Get image filenames from each directory and combine them\n",
    "train_image_filenames = [f for f in os.listdir(train_images_path) if f.endswith('.jpg')]\n",
    "val_image_filenames = [f for f in os.listdir(val_images_path) if f.endswith('.jpg')]\n",
    "test_image_filenames = [f for f in os.listdir(test_images_path) if f.endswith('.jpg')]\n",
    "\n",
    "\n",
    "test_relevant_annotations = [ann for ann in annotations_data if any(img in ann for img in test_image_filenames)]\n",
    "train_relevant_annotations = [ann for ann in annotations_data if any(img in ann for img in train_image_filenames)]\n",
    "\n",
    "val_relevant_annotations = [ann for ann in annotations_data if any(img in ann for img in val_image_filenames)]\n",
    "\n",
    "print(val_relevant_annotations)\n",
    "print(len(train_relevant_annotations))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9WlFcaRUeXoG"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def convert_to_yolo_format(annotation, image_path):\n",
    "    \"\"\"\n",
    "    Convert COCO-Hand annotation to YOLO format.\n",
    "    \"\"\"\n",
    "    # Extract bounding box coordinates\n",
    "    parts = annotation.split(',')\n",
    "    image_name = parts[0]\n",
    "    xmin, xmax, ymin, ymax = map(float, parts[1:5])\n",
    "\n",
    "    # Calculate absolute width and height\n",
    "    width_abs = abs(xmax - xmin)\n",
    "    height_abs = abs(ymax - ymin)\n",
    "\n",
    "    # Load the image to get its width and height\n",
    "    with Image.open(image_path) as img:\n",
    "        img_width, img_height = img.size\n",
    "\n",
    "    # Calculate YOLO format values\n",
    "    x_center = ((xmin + xmax) / 2) / img_width\n",
    "    y_center = ((ymin + ymax) / 2) / img_height\n",
    "    width = width_abs / img_width\n",
    "    height = height_abs / img_height\n",
    "\n",
    "    return [0, x_center, y_center, width, height]  # 0 is the class_id for 'hand'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RwWdoOisegk7",
    "outputId": "fe24a126-a8c6-43cd-f862-9eb906fec028"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Creating a dictionary to store annotations for each image for TEST dataset\n",
    "print(test_relevant_annotations)\n",
    "test_annotations_dict = {}\n",
    "for ann in test_relevant_annotations:\n",
    "    image_name = ann.split(',')[0]\n",
    "    if image_name not in test_annotations_dict:\n",
    "        test_annotations_dict[image_name] = []\n",
    "    test_annotations_dict[image_name].append(ann)\n",
    "print(test_annotations_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ewn3DogYegnd",
    "outputId": "714bc2aa-cebe-4c31-bf6b-03981f84948e"
   },
   "outputs": [],
   "source": [
    "#Create a dictionary to store annotations for each image for train dataset\n",
    "train_annotations_dict = {}\n",
    "for ann in train_relevant_annotations:\n",
    "    image_name = ann.split(',')[0]\n",
    "    if image_name not in train_annotations_dict:\n",
    "        train_annotations_dict[image_name] = []\n",
    "    train_annotations_dict[image_name].append(ann)\n",
    "print(len(train_annotations_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zlQALFtgegqH",
    "outputId": "00777647-f419-4144-8287-e7946b732362"
   },
   "outputs": [],
   "source": [
    "#Create a dictionary to store annotations for each image for val dataset\n",
    "val_annotations_dict = {}\n",
    "for ann in val_relevant_annotations:\n",
    "    image_name = ann.split(',')[0]\n",
    "    if image_name not in val_annotations_dict:\n",
    "        val_annotations_dict[image_name] = []\n",
    "    val_annotations_dict[image_name].append(ann)\n",
    "print(val_annotations_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pg3XNHG_egsr"
   },
   "outputs": [],
   "source": [
    "# Convert each annotation to YOLO format and save to .txt file for TEST IMAGES\n",
    "\n",
    "\n",
    "\n",
    "for image_name, image_annotations in test_annotations_dict.items():\n",
    "    yolo_formatted_annotations = [convert_to_yolo_format(ann, os.path.join(test_images_path, image_name)) for ann in image_annotations]  # Use image_annotations instead of test_relevant_annotations\n",
    "    yolo_strings = [\" \".join(map(str, ann)) for ann in yolo_formatted_annotations]\n",
    "\n",
    "    txt_path = os.path.join(test_labels_path, image_name.replace('.jpg', '.txt'))\n",
    "\n",
    "    labels_directory = os.path.dirname(txt_path)\n",
    "    if not os.path.exists(labels_directory):\n",
    "      os.makedirs(labels_directory)\n",
    "\n",
    "    with open(txt_path, 'w') as f:\n",
    "        f.write(\"\\n\".join(yolo_strings))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oiNq0r8Cegu3"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Convert each annotation to YOLO format and save to .txt file FOR TRAIN IMAGES\n",
    "for image_name, image_annotations in train_annotations_dict.items():\n",
    "    yolo_formatted_annotations = [convert_to_yolo_format(ann, os.path.join(train_images_path, image_name)) for ann in image_annotations]\n",
    "    yolo_strings = [\" \".join(map(str, ann)) for ann in yolo_formatted_annotations]\n",
    "\n",
    "    txt_path = os.path.join(train_labels_path, image_name.replace('.jpg', '.txt'))\n",
    "\n",
    "    labels_directory = os.path.dirname(txt_path)\n",
    "    if not os.path.exists(labels_directory):\n",
    "      os.makedirs(labels_directory)\n",
    "\n",
    "    with open(txt_path, 'w') as f:\n",
    "        f.write(\"\\n\".join(yolo_strings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "arSomNr0egyJ"
   },
   "outputs": [],
   "source": [
    "# Convert each annotation to YOLO format and save to .txt file FOR VAL IMAGES\n",
    "for image_name, image_annotations in val_annotations_dict.items():\n",
    "    yolo_formatted_annotations = [convert_to_yolo_format(ann, os.path.join(val_images_path, image_name)) for ann in image_annotations]\n",
    "    yolo_strings = [\" \".join(map(str, ann)) for ann in yolo_formatted_annotations]\n",
    "\n",
    "    txt_path = os.path.join(val_labels_path, image_name.replace('.jpg', '.txt'))\n",
    "\n",
    "    labels_directory = os.path.dirname(txt_path)\n",
    "    if not os.path.exists(labels_directory):\n",
    "      os.makedirs(labels_directory)\n",
    "\n",
    "    with open(txt_path, 'w') as f:\n",
    "        f.write(\"\\n\".join(yolo_strings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F0wiGvjMhWAF"
   },
   "outputs": [],
   "source": [
    "#Creating the YAML file\n",
    "def create_yaml_configuration():\n",
    "    \"\"\"\n",
    "    Creates a .YAML configuration file for training YOLO.\n",
    "    Returns the path to the created .YAML file.\n",
    "    \"\"\"\n",
    "    # Define the content for the .YAML configuration file\n",
    "    yaml_content = \"\"\"\n",
    "    train: /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train\n",
    "    test: /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/test\n",
    "    val: /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/val\n",
    "\n",
    "    # Classes\n",
    "    nc: 1\n",
    "    names: ['hand']\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the path for the .YAML file\n",
    "    yaml_path = Path(os.path.expanduser(\"~/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/coco_hand_big.yaml\"))\n",
    "\n",
    "    # Write the content to the .YAML file\n",
    "    with open(yaml_path, 'w') as yaml_file:\n",
    "        yaml_file.write(yaml_content)\n",
    "\n",
    "    # Return the path to the created .YAML file\n",
    "    return yaml_path\n",
    "\n",
    "create_yaml_configuration()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "8bBRmUvqhA5w"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.208 🚀 Python-3.9.7 torch-1.13.1 CUDA:0 (NVIDIA TITAN RTX, 24220MiB)\n",
      "WARNING ⚠️ Upgrade to torch>=2.0.0 for deterministic training.\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.pt, data=/home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/coco_hand_big.yaml, epochs=100, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=COCO-Hand, name=COCO_Hand_Big2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=COCO-Hand/COCO_Hand_Big2\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3776275  ultralytics.nn.modules.head.Detect           [1, [192, 384, 576]]          \n",
      "Model summary: 295 layers, 25856899 parameters, 25856883 gradients, 79.1 GFLOPs\n",
      "\n",
      "Transferred 469/475 items from pretrained weights\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/nikhil/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/nikhil/Documents/inseer_ML_Project/yolov8/Nikhil-yolov8 training/wandb/run-20231111_233217-6jxyvvkd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dugyalanikhil/COCO-Hand/runs/6jxyvvkd\" target=\"_blank\">COCO_Hand_Big2</a></strong> to <a href=\"https://wandb.ai/dugyalanikhil/COCO-Hand\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href=\"https://wandb.ai/dugyalanikhil/COCO-Hand\" target=\"_blank\">https://wandb.ai/dugyalanikhil/COCO-Hand</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href=\"https://wandb.ai/dugyalanikhil/COCO-Hand/runs/6jxyvvkd\" target=\"_blank\">https://wandb.ai/dugyalanikhil/COCO-Hand/runs/6jxyvvkd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to 'yolov8n.pt'...\n",
      "100%|██████████| 6.23M/6.23M [00:00<00:00, 72.9MB/s]\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks failed ❌. Anomalies were detected with AMP on your system that may lead to NaN losses or zero-mAP results, so AMP will be disabled during training.\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/labels.cache... 21199 images, 0 backgrounds, 197 corrupt: 100%|██████████| 21199/21199 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000000036.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0069]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000001668.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0028]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000006407.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0146]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000010313.jpg: ignoring corrupt image/label: negative label values [ -0.0041667]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000011138.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0347]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000011258.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0222]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000015335.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0264]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000020698.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0083]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000032954.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0403]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000038845.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0431]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000039743.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0014]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000040338.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0194]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000041710.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0014]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000041796.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0667]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000041818.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0139]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000042553.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0264      1.0528]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000049346.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0042]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000054282.jpg: ignoring corrupt image/label: negative label values [     -0.025]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000054532.jpg: ignoring corrupt image/label: negative label values [  -0.029167]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000056455.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0552]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000056473.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0375]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000057995.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0333]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000060775.jpg: ignoring corrupt image/label: negative label values [  -0.019444]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000063698.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0083]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000068650.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0042]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000071157.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0521]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000075754.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0458]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000078703.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0014]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000081967.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0431]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000089154.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000097502.jpg: ignoring corrupt image/label: negative label values [  -0.021875]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000099067.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.049]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000100238.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0069]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000101369.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0069]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000101877.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0014]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000105961.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0208]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000108313.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0042]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000109602.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000110252.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0069]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000114389.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0056]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000115108.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0528]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000117300.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0458]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000119884.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0375]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000121706.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0264]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000125661.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0167]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000126808.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0028]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000128599.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0431]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000131364.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0222]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000134193.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0063]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000138370.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0056]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000141634.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0444]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000147172.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0042]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000149233.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0056]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000149615.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0681]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000149774.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0319]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000152293.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0056]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000155794.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0014]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000156180.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0403]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000160443.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0069]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000164102.jpg: ignoring corrupt image/label: negative label values [    -0.0125]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000167489.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0208      1.0181]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000167724.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0444]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000167927.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0319]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000173008.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0153]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000175102.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0083]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000177636.jpg: ignoring corrupt image/label: negative label values [  -0.023611]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000179961.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0389]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000189224.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0139]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000189280.jpg: ignoring corrupt image/label: negative label values [ -0.0052083]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000196377.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0333]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000197369.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0486]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000203177.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0292]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000203629.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0028]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000207010.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0306]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000207611.jpg: ignoring corrupt image/label: negative label values [ -0.0020833]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000213408.jpg: ignoring corrupt image/label: negative label values [  -0.027083]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000214692.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0125]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000219674.jpg: ignoring corrupt image/label: negative label values [ -0.0013889]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000227003.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0458]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000228910.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0056]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000232801.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0153]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000233871.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0514]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000235541.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0028]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000240043.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0042]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000250881.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0083]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000251367.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000254177.jpg: ignoring corrupt image/label: negative label values [  -0.010417]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000256087.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0139]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000257470.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0069]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000260478.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0115]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000261271.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0139]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000274724.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0028]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000281573.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0278]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000284220.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0125]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000285437.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0403]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000291417.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0097]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000292358.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0153]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000295745.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0333]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000300721.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0042]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000304390.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0028]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000311808.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0319]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000318953.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0208]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000323599.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0111]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000323960.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0056]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000327073.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0069]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000332571.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0139]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000333356.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0167]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000337304.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0069]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000340331.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0444]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000341062.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0056]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000341886.jpg: ignoring corrupt image/label: negative label values [ -0.0041667]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000346270.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0597]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000346521.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0125]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000348371.jpg: ignoring corrupt image/label: negative label values [  -0.039583]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000349827.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0014]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000350313.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0264]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000353720.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0028]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000354094.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0486]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000354794.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0375]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000355480.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0333      1.0181      1.0056]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000356749.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0181]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000356764.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0229]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000357743.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0042]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000357898.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0083]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000360447.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0556]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000360880.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.025]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000361222.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0222]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000364359.jpg: ignoring corrupt image/label: negative label values [ -0.0020833]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000368844.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0014]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000371015.jpg: ignoring corrupt image/label: negative label values [  -0.015278]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000371854.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0083]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000382125.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0187]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000383087.jpg: ignoring corrupt image/label: negative label values [  -0.034375]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000389453.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0069]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000392871.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0306]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000393724.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0236]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000396927.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.025]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000399628.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0111]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000400850.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0417]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000406294.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0625]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000408755.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0153]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000409100.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0125]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000409877.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0069]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000412362.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0042]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000412681.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0236]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000413377.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0181]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000415109.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0153]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000422877.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0083]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000423046.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0042]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000426300.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0014]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000431439.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0014]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000434067.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0031]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000443243.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0125]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000443556.jpg: ignoring corrupt image/label: negative label values [ -0.0041667]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000446539.jpg: ignoring corrupt image/label: negative label values [  -0.053125]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000459110.jpg: ignoring corrupt image/label: negative label values [  -0.026042]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000463452.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0542]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000463839.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0375]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000467887.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0125]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000469085.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0125]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000472426.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0014]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000472519.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0222]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000479808.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0181]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000480474.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0125]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000481689.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0083]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000484551.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0069]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000487567.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0667]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000489827.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0347]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000492078.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0069]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000492638.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0264]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000492840.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0139]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000501015.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0125]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000502163.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0194]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000504769.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0042]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000506920.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0306]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000509225.jpg: ignoring corrupt image/label: negative label values [ -0.0041667]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000510790.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0042]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000510959.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0236]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000514362.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0361]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000516176.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0111      1.0222]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000516725.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0458]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000517819.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0097]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000533407.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0264]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000535060.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0083]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000536059.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0052]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000543272.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0278]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000545114.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0569]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000547509.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.025]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000555170.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0375]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000559760.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0375]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000565781.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0222]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000566064.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0375]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000566188.jpg: ignoring corrupt image/label: negative label values [    -0.0125]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000566498.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0556]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000566584.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0222]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000572233.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0083]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000572391.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0333]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000572456.jpg: ignoring corrupt image/label: negative label values [ -0.0020833]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000572902.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0097]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000578341.jpg: ignoring corrupt image/label: negative label values [  -0.020833]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/val/labels.cache... 2650 images, 0 backgrounds, 15 corrupt: 100%|██████████| 2650/2650 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/val/images/000000076170.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0556]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/val/images/000000096566.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0198]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/val/images/000000115521.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0583]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/val/images/000000126356.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0514]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/val/images/000000130239.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0153]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/val/images/000000164871.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0181]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/val/images/000000185634.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0097]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/val/images/000000204759.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0097]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/val/images/000000258688.jpg: ignoring corrupt image/label: negative label values [ -0.0020833]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/val/images/000000317112.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0094]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/val/images/000000363252.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0111]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/val/images/000000418229.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0347]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/val/images/000000508730.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0042]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/val/images/000000569878.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0181]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/val/images/000000572362.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0014]\n",
      "Plotting labels to COCO-Hand/COCO_Hand_Big2/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mCOCO-Hand/COCO_Hand_Big2\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "  0%|          | 0/1313 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 226.00 MiB (GPU 0; 23.65 GiB total capacity; 4.90 GiB already allocated; 150.62 MiB free; 5.12 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain(data\u001b[38;5;241m=\u001b[39mdata_yaml, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, project\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCOCO-Hand\u001b[39m\u001b[38;5;124m\"\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCOCO_Hand_Big\u001b[39m\u001b[38;5;124m\"\u001b[39m, imgsz\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m640\u001b[39m)\n\u001b[1;32m      6\u001b[0m     model\u001b[38;5;241m.\u001b[39mval()\n\u001b[0;32m----> 8\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/coco_hand_big.yaml\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 5\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(data_yaml)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_model\u001b[39m(data_yaml):\n\u001b[1;32m      4\u001b[0m     model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myolov8m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_yaml\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCOCO-Hand\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCOCO_Hand_Big\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m640\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     model\u001b[38;5;241m.\u001b[39mval()\n",
      "File \u001b[0;32m~/anaconda3/envs/yolov8/lib/python3.9/site-packages/ultralytics/engine/model.py:338\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mhub_session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[0;32m--> 338\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/yolov8/lib/python3.9/site-packages/ultralytics/engine/trainer.py:190\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    187\u001b[0m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/yolov8/lib/python3.9/site-packages/ultralytics/engine/trainer.py:337\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mautocast(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mamp):\n\u001b[1;32m    336\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_batch(batch)\n\u001b[0;32m--> 337\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_items \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    339\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m world_size\n",
      "File \u001b[0;32m~/anaconda3/envs/yolov8/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/yolov8/lib/python3.9/site-packages/ultralytics/nn/tasks.py:41\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03mForward pass of the model on a single scale. Wrapper for `_forward_once` method.\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;03m    (torch.Tensor): The output of the network.\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/yolov8/lib/python3.9/site-packages/ultralytics/nn/tasks.py:211\u001b[0m, in \u001b[0;36mBaseModel.loss\u001b[0;34m(self, batch, preds)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcriterion\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_criterion()\n\u001b[0;32m--> 211\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m preds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m preds\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(preds, batch)\n",
      "File \u001b[0;32m~/anaconda3/envs/yolov8/lib/python3.9/site-packages/ultralytics/nn/tasks.py:42\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/yolov8/lib/python3.9/site-packages/ultralytics/nn/tasks.py:59\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[0;34m(self, x, profile, visualize, augment)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[0;32m---> 59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/yolov8/lib/python3.9/site-packages/ultralytics/nn/tasks.py:79\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[0;34m(self, x, profile, visualize)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[0;32m---> 79\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[1;32m     80\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "File \u001b[0;32m~/anaconda3/envs/yolov8/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/yolov8/lib/python3.9/site-packages/ultralytics/nn/modules/block.py:204\u001b[0m, in \u001b[0;36mC2f.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    202\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x)\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    203\u001b[0m y\u001b[38;5;241m.\u001b[39mextend(m(y[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm)\n\u001b[0;32m--> 204\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 226.00 MiB (GPU 0; 23.65 GiB total capacity; 4.90 GiB already allocated; 150.62 MiB free; 5.12 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "#Train model\n",
    "def train_model(data_yaml):\n",
    "\n",
    "    model = YOLO(\"yolov8m.pt\")\n",
    "    model.train(data=data_yaml, epochs=100, project=\"COCO-Hand\", name=\"COCO_Hand_Big\", imgsz=640)\n",
    "    model.val()\n",
    "    \n",
    "train_model('/home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/coco_hand_big.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "a7at1IoK5zsR"
   },
   "outputs": [],
   "source": [
    "#Train model using previous weights\n",
    "\n",
    "def train_model(data_yaml, weights_path=None, additional_epochs=100, batch_size=16):\n",
    "    \"\"\"\n",
    "    Train the YOLOv8 model on the COCO Big Hand dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    model = YOLO(weights_path)\n",
    "\n",
    "    # Set the batch size for training\n",
    "    model.batch_size = batch_size  \n",
    "\n",
    "    # Continue training the model with the specified batch size\n",
    "    model.train(data=data_yaml, epochs=additional_epochs, project=\"COCO-Hand\", name=\"COCO_Hand_Big\", imgsz=640)\n",
    "    model.val()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r2I3kUXkguSI",
    "outputId": "f4ac04a4-a94e-415a-9636-c48e52023fcd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.208 🚀 Python-3.9.7 torch-1.13.1 CUDA:0 (NVIDIA TITAN RTX, 24220MiB)\n",
      "WARNING ⚠️ Upgrade to torch>=2.0.0 for deterministic training.\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/home/nikhil/Documents/Training_weights/COCO_Trained model weights 45 epochs/COCO_Trained model weights 45 epochs /COCO_Hand_Big/weights/best.pt, data=/home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/coco_hand_big.yaml, epochs=100, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=COCO-Hand, name=COCO_Hand_Big, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=COCO-Hand/COCO_Hand_Big\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3776275  ultralytics.nn.modules.head.Detect           [1, [192, 384, 576]]          \n",
      "Model summary: 295 layers, 25856899 parameters, 25856883 gradients, 79.1 GFLOPs\n",
      "\n",
      "Transferred 475/475 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks failed ❌. Anomalies were detected with AMP on your system that may lead to NaN losses or zero-mAP results, so AMP will be disabled during training.\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/labels.cache... 21199 images, 0 backgrounds, 197 corrupt: 100%|██████████| 21199/21199 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000000036.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0069]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000001668.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0028]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000006407.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0146]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000010313.jpg: ignoring corrupt image/label: negative label values [ -0.0041667]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000011138.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0347]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000011258.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0222]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000015335.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0264]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000020698.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0083]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000032954.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0403]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000038845.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0431]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000039743.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0014]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000040338.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0194]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000041710.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0014]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000041796.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0667]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000041818.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0139]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000042553.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0264      1.0528]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000049346.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0042]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000054282.jpg: ignoring corrupt image/label: negative label values [     -0.025]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000054532.jpg: ignoring corrupt image/label: negative label values [  -0.029167]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000056455.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0552]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000056473.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0375]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000057995.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0333]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000060775.jpg: ignoring corrupt image/label: negative label values [  -0.019444]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000063698.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0083]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000068650.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0042]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000071157.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0521]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000075754.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0458]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000078703.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0014]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000081967.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0431]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000089154.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000097502.jpg: ignoring corrupt image/label: negative label values [  -0.021875]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000099067.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.049]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000100238.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0069]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000101369.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0069]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000101877.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0014]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000105961.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0208]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000108313.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0042]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000109602.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000110252.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0069]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000114389.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0056]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000115108.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0528]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000117300.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0458]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000119884.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0375]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000121706.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0264]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000125661.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0167]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000126808.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0028]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000128599.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0431]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000131364.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0222]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000134193.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0063]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000138370.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0056]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000141634.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0444]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000147172.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0042]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000149233.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0056]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000149615.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0681]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000149774.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0319]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000152293.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0056]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000155794.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0014]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000156180.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0403]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000160443.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0069]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000164102.jpg: ignoring corrupt image/label: negative label values [    -0.0125]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000167489.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0208      1.0181]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000167724.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0444]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000167927.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0319]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000173008.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0153]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000175102.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0083]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000177636.jpg: ignoring corrupt image/label: negative label values [  -0.023611]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000179961.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0389]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000189224.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0139]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000189280.jpg: ignoring corrupt image/label: negative label values [ -0.0052083]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000196377.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0333]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000197369.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0486]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000203177.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0292]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000203629.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0028]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000207010.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0306]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000207611.jpg: ignoring corrupt image/label: negative label values [ -0.0020833]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000213408.jpg: ignoring corrupt image/label: negative label values [  -0.027083]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000214692.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0125]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000219674.jpg: ignoring corrupt image/label: negative label values [ -0.0013889]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000227003.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0458]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000228910.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0056]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000232801.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0153]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000233871.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0514]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000235541.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0028]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000240043.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0042]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000250881.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0083]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000251367.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000254177.jpg: ignoring corrupt image/label: negative label values [  -0.010417]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000256087.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0139]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000257470.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0069]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000260478.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0115]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000261271.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0139]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000274724.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0028]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000281573.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0278]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000284220.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0125]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000285437.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0403]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000291417.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0097]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000292358.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0153]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000295745.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0333]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000300721.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0042]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000304390.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0028]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000311808.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0319]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000318953.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0208]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000323599.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0111]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000323960.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0056]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000327073.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0069]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000332571.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0139]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000333356.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0167]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000337304.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0069]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000340331.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0444]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000341062.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0056]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000341886.jpg: ignoring corrupt image/label: negative label values [ -0.0041667]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000346270.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0597]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000346521.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0125]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000348371.jpg: ignoring corrupt image/label: negative label values [  -0.039583]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000349827.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0014]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000350313.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0264]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000353720.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0028]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000354094.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0486]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000354794.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0375]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000355480.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0333      1.0181      1.0056]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000356749.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0181]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000356764.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0229]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000357743.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0042]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000357898.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0083]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000360447.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0556]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000360880.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.025]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000361222.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0222]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000364359.jpg: ignoring corrupt image/label: negative label values [ -0.0020833]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000368844.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0014]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000371015.jpg: ignoring corrupt image/label: negative label values [  -0.015278]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000371854.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0083]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000382125.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0187]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000383087.jpg: ignoring corrupt image/label: negative label values [  -0.034375]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000389453.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0069]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000392871.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0306]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000393724.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0236]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000396927.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.025]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000399628.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0111]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000400850.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0417]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000406294.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0625]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000408755.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0153]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000409100.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0125]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000409877.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0069]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000412362.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0042]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000412681.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0236]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000413377.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0181]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000415109.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0153]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000422877.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0083]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000423046.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0042]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000426300.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0014]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000431439.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0014]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000434067.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0031]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000443243.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0125]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000443556.jpg: ignoring corrupt image/label: negative label values [ -0.0041667]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000446539.jpg: ignoring corrupt image/label: negative label values [  -0.053125]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000459110.jpg: ignoring corrupt image/label: negative label values [  -0.026042]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000463452.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0542]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000463839.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0375]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000467887.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0125]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000469085.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0125]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000472426.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0014]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000472519.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0222]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000479808.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0181]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000480474.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0125]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000481689.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0083]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000484551.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0069]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000487567.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0667]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000489827.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0347]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000492078.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0069]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000492638.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0264]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000492840.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0139]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000501015.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0125]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000502163.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0194]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000504769.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0042]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000506920.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0306]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000509225.jpg: ignoring corrupt image/label: negative label values [ -0.0041667]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000510790.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0042]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000510959.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0236]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000514362.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0361]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000516176.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0111      1.0222]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000516725.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0458]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000517819.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0097]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000533407.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0264]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000535060.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0083]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000536059.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0052]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000543272.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0278]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000545114.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0569]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000547509.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.025]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000555170.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0375]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000559760.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0375]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000565781.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0222]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000566064.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0375]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000566188.jpg: ignoring corrupt image/label: negative label values [    -0.0125]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000566498.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0556]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000566584.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0222]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000572233.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0083]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000572391.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0333]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000572456.jpg: ignoring corrupt image/label: negative label values [ -0.0020833]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000572902.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0097]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/train/images/000000578341.jpg: ignoring corrupt image/label: negative label values [  -0.020833]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/val/labels.cache... 2650 images, 0 backgrounds, 15 corrupt: 100%|██████████| 2650/2650 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/val/images/000000076170.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0556]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/val/images/000000096566.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0198]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/val/images/000000115521.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0583]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/val/images/000000126356.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0514]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/val/images/000000130239.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0153]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/val/images/000000164871.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0181]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/val/images/000000185634.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0097]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/val/images/000000204759.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0097]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/val/images/000000258688.jpg: ignoring corrupt image/label: negative label values [ -0.0020833]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/val/images/000000317112.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0094]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/val/images/000000363252.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0111]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/val/images/000000418229.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0347]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/val/images/000000508730.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0042]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/val/images/000000569878.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0181]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/val/images/000000572362.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0014]\n",
      "Plotting labels to COCO-Hand/COCO_Hand_Big/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mCOCO-Hand/COCO_Hand_Big\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      1/100      11.7G      1.633      1.022      1.259         20        640: 100%|██████████| 1313/1313 [10:43<00:00,  2.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 83/83 [00:14<00:00,  5.84it/s]\n",
      "                   all       2635       4928      0.824      0.678      0.752      0.416\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      2/100      11.7G      1.628      1.044      1.256         25        640: 100%|██████████| 1313/1313 [10:48<00:00,  2.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 83/83 [00:13<00:00,  6.20it/s]\n",
      "                   all       2635       4928      0.822      0.675       0.75      0.415\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      3/100      11.6G      1.656      1.054      1.267         49        640: 100%|██████████| 1313/1313 [10:54<00:00,  2.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 83/83 [00:13<00:00,  6.10it/s]\n",
      "                   all       2635       4928      0.813      0.655      0.724      0.382\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      4/100      11.6G      1.693      1.092       1.29         29        640: 100%|██████████| 1313/1313 [10:50<00:00,  2.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 83/83 [00:13<00:00,  6.12it/s]\n",
      "                   all       2635       4928      0.814      0.663      0.741      0.394\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      5/100      11.6G      1.683      1.075      1.283         28        640: 100%|██████████| 1313/1313 [10:54<00:00,  2.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 83/83 [00:13<00:00,  6.01it/s]\n",
      "                   all       2635       4928      0.823       0.66      0.737      0.394\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      6/100      11.6G      1.681      1.067      1.283         32        640: 100%|██████████| 1313/1313 [11:18<00:00,  1.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 83/83 [00:13<00:00,  6.02it/s]\n",
      "                   all       2635       4928      0.814      0.669       0.74      0.395\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      7/100      11.6G      1.673      1.059       1.28         32        640: 100%|██████████| 1313/1313 [10:58<00:00,  1.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 83/83 [00:13<00:00,  6.09it/s]\n",
      "                   all       2635       4928      0.805      0.671      0.736      0.394\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      8/100      11.6G      1.666      1.048      1.275         24        640: 100%|██████████| 1313/1313 [10:52<00:00,  2.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 83/83 [00:13<00:00,  6.12it/s]\n",
      "                   all       2635       4928      0.816      0.669      0.737      0.397\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      9/100      11.6G      1.659      1.048       1.27         47        640: 100%|██████████| 1313/1313 [10:53<00:00,  2.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 83/83 [00:13<00:00,  5.95it/s]\n",
      "                   all       2635       4928      0.818      0.672      0.745      0.395\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     10/100      11.6G       1.66      1.037      1.266         40        640: 100%|██████████| 1313/1313 [10:52<00:00,  2.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 83/83 [00:13<00:00,  6.10it/s]\n",
      "                   all       2635       4928      0.809      0.671      0.739      0.396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     11/100      11.6G       1.65      1.035      1.269         32        640: 100%|██████████| 1313/1313 [10:52<00:00,  2.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 83/83 [00:13<00:00,  6.02it/s]\n",
      "                   all       2635       4928      0.807      0.675      0.744      0.399\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     12/100      11.6G      1.643      1.026      1.261         29        640: 100%|██████████| 1313/1313 [10:52<00:00,  2.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 83/83 [00:13<00:00,  6.00it/s]\n",
      "                   all       2635       4928      0.823      0.684       0.75        0.4\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     13/100      11.6G      1.633      1.019      1.259         26        640: 100%|██████████| 1313/1313 [10:51<00:00,  2.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 83/83 [00:13<00:00,  6.08it/s]\n",
      "                   all       2635       4928      0.806      0.682      0.748      0.401\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     14/100      11.6G      1.632      1.016      1.254         25        640: 100%|██████████| 1313/1313 [10:53<00:00,  2.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 83/83 [00:13<00:00,  6.22it/s]\n",
      "                   all       2635       4928      0.802      0.688      0.742      0.401\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     15/100      11.6G      1.623      1.007      1.254         22        640: 100%|██████████| 1313/1313 [10:52<00:00,  2.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 83/83 [00:13<00:00,  6.10it/s]\n",
      "                   all       2635       4928      0.815      0.681       0.75      0.398\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     16/100      11.6G      1.622      1.001       1.25         34        640: 100%|██████████| 1313/1313 [10:53<00:00,  2.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 83/83 [00:13<00:00,  6.10it/s]\n",
      "                   all       2635       4928      0.805      0.689      0.748      0.403\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     17/100      11.6G      1.616     0.9956      1.246         29        640: 100%|██████████| 1313/1313 [10:53<00:00,  2.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 83/83 [00:13<00:00,  6.15it/s]\n",
      "                   all       2635       4928      0.816      0.681      0.747      0.403\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     18/100      11.6G      1.619     0.9953      1.251         32        640: 100%|██████████| 1313/1313 [10:51<00:00,  2.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 83/83 [00:13<00:00,  6.16it/s]\n",
      "                   all       2635       4928      0.808      0.688      0.746      0.404\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     19/100      11.6G      1.607     0.9887      1.243         37        640: 100%|██████████| 1313/1313 [11:12<00:00,  1.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 83/83 [00:13<00:00,  6.04it/s]\n",
      "                   all       2635       4928       0.82      0.693      0.753      0.405\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     20/100      11.6G      1.595     0.9738      1.238         38        640: 100%|██████████| 1313/1313 [11:01<00:00,  1.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 83/83 [00:13<00:00,  6.12it/s]\n",
      "                   all       2635       4928      0.818      0.687      0.753      0.406\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     21/100      11.6G      1.593      0.975      1.237         24        640: 100%|██████████| 1313/1313 [10:56<00:00,  2.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 83/83 [00:13<00:00,  6.00it/s]\n",
      "                   all       2635       4928      0.807      0.691      0.752      0.405\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     22/100      11.6G      1.593     0.9726      1.238          9        640: 100%|██████████| 1313/1313 [10:58<00:00,  1.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 83/83 [00:13<00:00,  5.96it/s]\n",
      "                   all       2635       4928      0.814      0.688      0.754      0.406\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     23/100      11.6G      1.585     0.9702      1.234         36        640: 100%|██████████| 1313/1313 [10:58<00:00,  1.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 83/83 [00:13<00:00,  6.06it/s]\n",
      "                   all       2635       4928      0.809      0.691      0.751      0.409\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     24/100      11.6G       1.58       0.96      1.228         32        640: 100%|██████████| 1313/1313 [11:23<00:00,  1.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 83/83 [00:13<00:00,  6.05it/s]\n",
      "                   all       2635       4928      0.815      0.686       0.75      0.408\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     25/100      11.6G      1.573     0.9559      1.227         25        640: 100%|██████████| 1313/1313 [10:59<00:00,  1.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 83/83 [00:13<00:00,  6.09it/s]\n",
      "                   all       2635       4928      0.815      0.695      0.756      0.409\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     26/100      11.6G       1.57     0.9483      1.223         50        640: 100%|██████████| 1313/1313 [10:58<00:00,  1.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 83/83 [00:13<00:00,  6.11it/s]\n",
      "                   all       2635       4928      0.812      0.696      0.755      0.411\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     27/100      11.6G      1.562     0.9439      1.224         34        640: 100%|██████████| 1313/1313 [10:58<00:00,  1.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 83/83 [00:13<00:00,  6.12it/s]\n",
      "                   all       2635       4928      0.811      0.691      0.755      0.411\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     28/100      11.6G       1.57     0.9468      1.223         32        640: 100%|██████████| 1313/1313 [10:58<00:00,  1.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 83/83 [00:13<00:00,  6.03it/s]\n",
      "                   all       2635       4928      0.805      0.699      0.756      0.412\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     29/100      11.6G      1.567     0.9387      1.221         32        640: 100%|██████████| 1313/1313 [10:58<00:00,  1.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 83/83 [00:13<00:00,  6.01it/s]\n",
      "                   all       2635       4928      0.817      0.691      0.756      0.411\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     30/100      11.6G      1.549      0.936      1.213         36        640: 100%|██████████| 1313/1313 [10:59<00:00,  1.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 83/83 [00:13<00:00,  5.99it/s]\n",
      "                   all       2635       4928       0.82       0.68      0.752       0.41\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     31/100      11.6G      1.545     0.9243      1.212         32        640: 100%|██████████| 1313/1313 [10:59<00:00,  1.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 83/83 [00:13<00:00,  6.11it/s]\n",
      "                   all       2635       4928      0.824      0.688      0.754      0.409\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     32/100      11.6G      1.552     0.9304      1.218         29        640: 100%|██████████| 1313/1313 [10:59<00:00,  1.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 83/83 [00:13<00:00,  6.11it/s]\n",
      "                   all       2635       4928       0.82      0.688      0.757       0.41\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     33/100      11.6G      1.539     0.9249      1.211         19        640: 100%|██████████| 1313/1313 [10:59<00:00,  1.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 83/83 [00:13<00:00,  6.04it/s]\n",
      "                   all       2635       4928      0.826      0.682      0.756      0.409\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     34/100      11.6G      1.527     0.9113      1.203         41        640: 100%|██████████| 1313/1313 [10:59<00:00,  1.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 83/83 [00:13<00:00,  6.10it/s]\n",
      "                   all       2635       4928      0.818      0.688      0.755       0.41\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     35/100      11.6G      1.535     0.9172      1.208         33        640: 100%|██████████| 1313/1313 [11:00<00:00,  1.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 83/83 [00:13<00:00,  6.04it/s]\n",
      "                   all       2635       4928      0.809      0.696      0.755      0.409\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     36/100      11.6G      1.526     0.9123        1.2         35        640: 100%|██████████| 1313/1313 [11:00<00:00,  1.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 83/83 [00:13<00:00,  5.98it/s]\n",
      "                   all       2635       4928       0.81      0.691      0.757       0.41\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     37/100      11.6G      1.527     0.9104      1.205         26        640: 100%|██████████| 1313/1313 [11:00<00:00,  1.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 83/83 [00:13<00:00,  5.93it/s]\n",
      "                   all       2635       4928      0.824      0.689      0.757       0.41\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     38/100      11.6G      1.514     0.8971      1.196         34        640: 100%|██████████| 1313/1313 [11:00<00:00,  1.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 83/83 [00:13<00:00,  6.01it/s]\n",
      "                   all       2635       4928      0.826       0.69      0.759      0.411\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     39/100      11.6G      1.507     0.8948      1.194         53        640: 100%|██████████| 1313/1313 [11:10<00:00,  1.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 83/83 [00:24<00:00,  3.35it/s]\n",
      "                   all       2635       4928      0.823      0.692       0.76      0.412\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     40/100      11.6G      1.502     0.8909      1.195         31        640: 100%|██████████| 1313/1313 [11:04<00:00,  1.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 83/83 [00:14<00:00,  5.91it/s]\n",
      "                   all       2635       4928      0.816      0.693      0.756      0.411\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     41/100      11.6G      1.505      0.895      1.191         36        640: 100%|██████████| 1313/1313 [11:01<00:00,  1.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 83/83 [00:13<00:00,  6.01it/s]\n",
      "                   all       2635       4928      0.813      0.695      0.758      0.411\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     42/100      11.6G      1.493     0.8831      1.187         14        640: 100%|██████████| 1313/1313 [11:00<00:00,  1.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 83/83 [00:13<00:00,  6.13it/s]\n",
      "                   all       2635       4928      0.821       0.69      0.758      0.412\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     43/100      11.6G      1.497     0.8855      1.188         39        640: 100%|██████████| 1313/1313 [10:58<00:00,  2.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 83/83 [00:13<00:00,  6.01it/s]\n",
      "                   all       2635       4928      0.823      0.689      0.758      0.411\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     44/100      11.6G       1.49     0.8798      1.187         25        640: 100%|██████████| 1313/1313 [10:58<00:00,  1.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 83/83 [00:13<00:00,  6.05it/s]\n",
      "                   all       2635       4928      0.816      0.696      0.759      0.411\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     45/100      11.6G      1.486     0.8711      1.183         36        640: 100%|██████████| 1313/1313 [10:59<00:00,  1.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 83/83 [00:13<00:00,  6.03it/s]\n",
      "                   all       2635       4928      0.822      0.692      0.758      0.411\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     46/100      11.6G      1.481     0.8736      1.182         25        640: 100%|██████████| 1313/1313 [10:57<00:00,  2.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 83/83 [00:13<00:00,  6.03it/s]\n",
      "                   all       2635       4928      0.825       0.69      0.759      0.411\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     47/100      11.6G      1.474     0.8634      1.175         32        640: 100%|██████████| 1313/1313 [10:57<00:00,  2.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 83/83 [00:13<00:00,  6.08it/s]\n",
      "                   all       2635       4928      0.821      0.691      0.758      0.411\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     48/100      11.6G      1.474     0.8636      1.175         37        640: 100%|██████████| 1313/1313 [10:57<00:00,  2.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 83/83 [00:13<00:00,  6.08it/s]\n",
      "                   all       2635       4928      0.821       0.69      0.758      0.411\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     49/100      11.6G      1.468     0.8537      1.173         35        640: 100%|██████████| 1313/1313 [10:56<00:00,  2.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 83/83 [00:13<00:00,  6.16it/s]\n",
      "                   all       2635       4928       0.82      0.691      0.758      0.411\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     50/100      11.6G      1.463     0.8524      1.172         33        640: 100%|██████████| 1313/1313 [10:57<00:00,  2.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 83/83 [00:13<00:00,  6.01it/s]\n",
      "                   all       2635       4928      0.816      0.695      0.758      0.411\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     51/100      11.6G       1.45     0.8461      1.166         19        640: 100%|██████████| 1313/1313 [10:55<00:00,  2.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 83/83 [00:13<00:00,  6.11it/s]\n",
      "                   all       2635       4928       0.82      0.692      0.757      0.411\n",
      "Stopping training early as no improvement observed in last 50 epochs. Best results observed at epoch 1, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=50) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
      "\n",
      "51 epochs completed in 9.529 hours.\n",
      "Optimizer stripped from COCO-Hand/COCO_Hand_Big/weights/last.pt, 52.0MB\n",
      "Optimizer stripped from COCO-Hand/COCO_Hand_Big/weights/best.pt, 52.0MB\n",
      "\n",
      "Validating COCO-Hand/COCO_Hand_Big/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.208 🚀 Python-3.9.7 torch-1.13.1 CUDA:0 (NVIDIA TITAN RTX, 24220MiB)\n",
      "Model summary (fused): 218 layers, 25840339 parameters, 0 gradients, 78.7 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 83/83 [00:14<00:00,  5.58it/s]\n",
      "                   all       2635       4928      0.825      0.677      0.752      0.416\n",
      "Speed: 0.2ms preprocess, 3.3ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mCOCO-Hand/COCO_Hand_Big\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>▁▅█████▇▇▇▇▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃</td></tr><tr><td>lr/pg1</td><td>▁▅█████▇▇▇▇▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃</td></tr><tr><td>lr/pg2</td><td>▁▅█████▇▇▇▇▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃</td></tr><tr><td>metrics/mAP50(B)</td><td>▆▆▁▄▄▃▄▅▅▆▆▆▆▅▅▇▆▇▆▇▇▇▇▆▇▇▇▇▇██▇███████▆</td></tr><tr><td>metrics/mAP50-95(B)</td><td>██▁▃▄▃▄▄▄▅▅▄▅▅▆▆▆▆▆▆▇▇▇▇▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇█</td></tr><tr><td>metrics/precision(B)</td><td>▇▇▄▄▄▁▄▅▂▇▁▄▁▅▂▅▁▄▄▄▃▃▅▆▇█▅▂▂█▇▅▆▇▅▆▆▆▆█</td></tr><tr><td>metrics/recall(B)</td><td>▅▄▁▂▃▄▃▄▄▆▆▆▇▅▇▆▇▇▆██▇▇▅▇▆▇█▇▇▇▇▇▇█▇▇▇▇▅</td></tr><tr><td>model/GFLOPs</td><td>▁</td></tr><tr><td>model/parameters</td><td>▁</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>▁</td></tr><tr><td>train/box_loss</td><td>▆▆▇██▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁</td></tr><tr><td>train/cls_loss</td><td>▆▇▇█▇▇▇▇▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>train/dfl_loss</td><td>▆▆▇██▇▇▇▇▆▆▆▆▆▆▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁</td></tr><tr><td>val/box_loss</td><td>▁▁█▆▆▇▆▆▅▇▆▆▆▅▅▅▅▅▅▅▅▅▄▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅</td></tr><tr><td>val/cls_loss</td><td>▃▄█▆▆▆▆▆▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/dfl_loss</td><td>▁▁█▅▅▅▅▅▄▅▄▅▄▄▄▄▃▄▄▄▄▄▄▄▄▄▄▅▄▄▅▅▅▅▅▅▅▆▆▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>0.00515</td></tr><tr><td>lr/pg1</td><td>0.00515</td></tr><tr><td>lr/pg2</td><td>0.00515</td></tr><tr><td>metrics/mAP50(B)</td><td>0.75173</td></tr><tr><td>metrics/mAP50-95(B)</td><td>0.41607</td></tr><tr><td>metrics/precision(B)</td><td>0.82494</td></tr><tr><td>metrics/recall(B)</td><td>0.67701</td></tr><tr><td>model/GFLOPs</td><td>79.066</td></tr><tr><td>model/parameters</td><td>25856899</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>3.317</td></tr><tr><td>train/box_loss</td><td>1.4504</td></tr><tr><td>train/cls_loss</td><td>0.84611</td></tr><tr><td>train/dfl_loss</td><td>1.16629</td></tr><tr><td>val/box_loss</td><td>1.59701</td></tr><tr><td>val/cls_loss</td><td>0.83358</td></tr><tr><td>val/dfl_loss</td><td>1.30449</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">COCO_Hand_Big2</strong> at: <a href=\"https://wandb.ai/dugyalanikhil/COCO-Hand/runs/6jxyvvkd\" target=\"_blank\">https://wandb.ai/dugyalanikhil/COCO-Hand/runs/6jxyvvkd</a><br/>Synced 3 W&B file(s), 21 media file(s), 5 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231111_233217-6jxyvvkd/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.208 🚀 Python-3.9.7 torch-1.13.1 CUDA:0 (NVIDIA TITAN RTX, 24220MiB)\n",
      "Model summary (fused): 218 layers, 25840339 parameters, 0 gradients, 78.7 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/val/labels.cache... 2650 images, 0 backgrounds, 15 corrupt: 100%|██████████| 2650/2650 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/val/images/000000076170.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0556]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/val/images/000000096566.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0198]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/val/images/000000115521.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0583]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/val/images/000000126356.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0514]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/val/images/000000130239.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0153]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/val/images/000000164871.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0181]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/val/images/000000185634.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0097]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/val/images/000000204759.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0097]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/val/images/000000258688.jpg: ignoring corrupt image/label: negative label values [ -0.0020833]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/val/images/000000317112.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0094]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/val/images/000000363252.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0111]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/val/images/000000418229.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0347]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/val/images/000000508730.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0042]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/val/images/000000569878.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0181]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/val/images/000000572362.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0014]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 165/165 [00:24<00:00,  6.61it/s]\n",
      "                   all       2635       4928      0.825      0.678      0.752      0.416\n",
      "Speed: 0.2ms preprocess, 6.8ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mCOCO-Hand/COCO_Hand_Big2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    data_yaml_path = '/home/nikhil/Documents/Datasets/COCO dataset/COCO-Hand-splitdata/coco_hand_big.yaml'\n",
    "    previous_weights_path = Path(os.path.expanduser(\"~/Documents/Training_weights/COCO_Trained model weights 45 epochs/COCO_Trained model weights 45 epochs /COCO_Hand_Big/weights/best.pt\"))\n",
    "\n",
    "    # Continue training for additional epochs using the weights from the last checkpoint\n",
    "    train_model(data_yaml_path, weights_path=previous_weights_path, additional_epochs=100,batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QrCk2D6thSpc"
   },
   "outputs": [],
   "source": [
    "#Uploading weights to drive\n",
    "def upload_file_to_drive(source_path, destination_path):\n",
    "    \"\"\"\n",
    "    Uploads a file from the Colab environment to Google Drive.\n",
    "\n",
    "    Parameters:\n",
    "    - source_path: The path to the file in the Colab environment.\n",
    "    - destination_path: The path in Google Drive where the file will be stored.\n",
    "    \"\"\"\n",
    "    # Ensure the destination directory exists\n",
    "    os.makedirs(os.path.dirname(destination_path), exist_ok=True)\n",
    "\n",
    "    # Copy the file to the destination directory\n",
    "    shutil.copy(source_path, destination_path)\n",
    "    print(f\"File {source_path} uploaded to {destination_path}\")\n",
    "\n",
    "\n",
    "upload_file_to_drive('/content/COCO-Hand', '/content/drive/Shareddrives/Nikhil shared drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wj5KlQC_MoCI"
   },
   "outputs": [],
   "source": [
    "#Testing model starts from here\n",
    "#Loading the weights\n",
    "!cp -r \"/content/drive/Shareddrives/Nikhil shared drive/COCO_Trained model weights 45 epochs /COCO_Hand_Big/weights/best.pt\" \"/content\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9j8moqluPjXU"
   },
   "outputs": [],
   "source": [
    "#plotting the bounding coordinates on images\n",
    "def plot_one_box(xyxy, img, label=None, color=None, line_thickness=None):\n",
    "    \"\"\"\n",
    "    Plots one bounding box on an image using OpenCV.\n",
    "\n",
    "    Args:\n",
    "    - xyxy (list): List of 4 values representing the bounding box coordinates [x1, y1, x2, y2].\n",
    "    - img (numpy.ndarray): Image on which to draw the bounding box.\n",
    "    - label (str, optional): Label to display above the bounding box.\n",
    "    - color (tuple, optional): Color of the bounding box. Default is red.\n",
    "    - line_thickness (int, optional): Thickness of the bounding box lines.\n",
    "\n",
    "    Returns:\n",
    "    - numpy.ndarray: Image with the bounding box drawn.\n",
    "    \"\"\"\n",
    "    color = color or [0, 0, 255]  # Default color is red\n",
    "    line_thickness = line_thickness or 2  # Default line thickness is 2\n",
    "    c1, c2 = (int(xyxy[0]), int(xyxy[1])), (int(xyxy[2]), int(xyxy[3]))\n",
    "    cv2.rectangle(img, c1, c2, color, thickness=line_thickness)\n",
    "    if label:\n",
    "        t_size = cv2.getTextSize(label, 0, fontScale=0.5, thickness=1)[0]\n",
    "        c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3\n",
    "        cv2.rectangle(img, c1, c2, color, -1)  # Negative thickness means filled rectangle\n",
    "        cv2.putText(img, label, (c1[0], c1[1] - 2), 0, 0.5, [225, 255, 255], thickness=1, lineType=cv2.LINE_AA)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iXZkPWEDEO5c"
   },
   "outputs": [],
   "source": [
    "#Testing the model\n",
    "def test_model(weights_path, image_dir, show=False):\n",
    "    \"\"\"\n",
    "    Test the trained YOLOv8 model on a set of images.\n",
    "    \"\"\"\n",
    "    image_dir = Path(image_dir)\n",
    "    model = YOLO(weights_path)\n",
    "\n",
    "    for image_path in image_dir.iterdir():\n",
    "        image = cv2.imread(image_path.as_posix())\n",
    "        results = model.predict(source=image, conf=0.3, iou=0.4)\n",
    "\n",
    "        # Extract the bounding boxes\n",
    "        detections = results[0].boxes.xyxy\n",
    "\n",
    "        # Attempt to extract confidence scores from the boxes\n",
    "        try:\n",
    "            confidences = [box[4].item() for box in detections]\n",
    "        except IndexError:\n",
    "            confidences = [1.0] * len(detections)  # Default to confidence of 1.0 if not available\n",
    "\n",
    "        # Check if there are any detections\n",
    "        if detections is not None:\n",
    "            for i, box in enumerate(detections):\n",
    "                xyxy = box[:4].tolist()\n",
    "                conf = confidences[i]\n",
    "                label = f'hand'  # Assuming only 'hand' class\n",
    "                plot_one_box(xyxy, image, label=label, color=(255, 0, 0), line_thickness=2)\n",
    "\n",
    "            if show:\n",
    "                plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "                plt.show()\n",
    "        else:\n",
    "            print(f\"No results for image {image_path.name}!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "id": "C5uYJxyI412c",
    "outputId": "56dbe4a4-974a-40c4-8b9e-675a01fc6ca2"
   },
   "outputs": [],
   "source": [
    "weights_path = \"/content/COCO_Trained model/COCO_Hand_Big/best (1).pt\"\n",
    "test_images_path = \"/content/drive/Shareddrives/Nikhil shared drive/hand14k/Images\"\n",
    "test_model(weights_path, test_images_path, show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4SRNglbF5vYl"
   },
   "source": [
    "Preprocessing the images, masks by cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "COzQx7h8-C9b"
   },
   "outputs": [],
   "source": [
    "zip_file_path = '/content/drive/Shareddrives/Nikhil shared drive/GTEA Cropped Dataset 6.6k Images/Cropped_Images.zip'\n",
    "extraction_path = '/content/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "epGrqwYr-D41",
    "outputId": "93881e81-78d8-4d5a-8531-bc688bdf5c80"
   },
   "outputs": [],
   "source": [
    "# Unzip the file\n",
    "with ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extraction_path)\n",
    "\n",
    "print(\"Unzipped successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P5b5P5lPM8T7"
   },
   "outputs": [],
   "source": [
    "def crop_mask_image(mask_dir, box, original_filename, scale=1.2):\n",
    "    \"\"\"\n",
    "    Crop the mask image using the same bounding box coordinates from the original image.\n",
    "\n",
    "    Args:\n",
    "    - mask_dir (str): Directory where the mask images are stored.\n",
    "    - box (list): List of 4 values representing the bounding box coordinates [x1, y1, x2, y2].\n",
    "    - original_filename (str): Filename of the original image to find the corresponding mask image.\n",
    "    - scale (float): Factor to scale the bounding box size.\n",
    "\n",
    "    Returns:\n",
    "    - numpy.ndarray: Cropped mask image.\n",
    "    \"\"\"\n",
    "    # Replace the extension of the original filename with .png\n",
    "    mask_filename = Path(original_filename).stem + '.png'\n",
    "\n",
    "    # Construct the full path for the mask image\n",
    "    mask_image_path = Path(mask_dir) / mask_filename\n",
    "    # Read the mask image\n",
    "    mask_image = cv2.imread(str(mask_image_path), cv2.IMREAD_UNCHANGED)\n",
    "    if mask_image is None:\n",
    "        raise FileNotFoundError(f\"The mask image at {mask_image_path} was not found.\")\n",
    "\n",
    "    # Calculate the size of the square bounding box\n",
    "    x1, y1, x2, y2 = box\n",
    "    width = x2 - x1\n",
    "    height = y2 - y1\n",
    "    side_length = max(width, height) * scale\n",
    "\n",
    "    # Calculate the center of the original bounding box\n",
    "    center_x = x1 + width / 2\n",
    "    center_y = y1 + height / 2\n",
    "\n",
    "    # Calculate the new bounding box coordinates\n",
    "    new_x1 = max(int(center_x - side_length / 2), 0)\n",
    "    new_y1 = max(int(center_y - side_length / 2), 0)\n",
    "    new_x2 = min(int(center_x + side_length / 2), mask_image.shape[1])\n",
    "    new_y2 = min(int(center_y + side_length / 2), mask_image.shape[0])\n",
    "\n",
    "    # Crop the mask image\n",
    "    cropped_mask = mask_image[new_y1:new_y2, new_x1:new_x2]\n",
    "\n",
    "    return cropped_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uvAW595GFDAt"
   },
   "outputs": [],
   "source": [
    "def save_cropped_image(image, save_dir, original_filename):\n",
    "    \"\"\"\n",
    "    Save the cropped image to the specified directory with the original filename.\n",
    "\n",
    "    Args:\n",
    "    - image (numpy.ndarray): The cropped image to save.\n",
    "    - save_dir (Path): The directory to save the cropped image.\n",
    "    - original_filename (str): The original filename for the cropped image.\n",
    "\n",
    "    Returns:\n",
    "    - str: The path to the saved image.\n",
    "    \"\"\"\n",
    "    # Create the directory if it doesn't exist\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Save the image\n",
    "    save_path = save_dir / original_filename\n",
    "    cv2.imwrite(str(save_path), image)\n",
    "\n",
    "    return str(save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rPENVtccAbQD"
   },
   "outputs": [],
   "source": [
    "#Cropping the images with (1.2 * s, 1.2 * s) scale\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def crop_and_resize(image, box, scale=1.2):\n",
    "    \"\"\"\n",
    "    Crop and resize the bounding box in the image.\n",
    "\n",
    "    Args:\n",
    "    - image (numpy.ndarray): The image from which to crop.\n",
    "    - box (list): The bounding box coordinates [x1, y1, x2, y2].\n",
    "    - scale (float): Factor to scale the bounding box size.\n",
    "\n",
    "    Returns:\n",
    "    - numpy.ndarray: The cropped and resized image.\n",
    "    \"\"\"\n",
    "    # Calculate width and height of the box\n",
    "    width = box[2] - box[0]\n",
    "    height = box[3] - box[1]\n",
    "    # Determine the size of the square\n",
    "    side_length = max(width, height)\n",
    "    # Calculate the new box coordinates, centered around the original box, with the new size\n",
    "    center_x, center_y = box[0] + width / 2, box[1] + height / 2\n",
    "    new_half_size = side_length * scale / 2\n",
    "    new_x1 = max(center_x - new_half_size, 0)\n",
    "    new_y1 = max(center_y - new_half_size, 0)\n",
    "    new_x2 = min(center_x + new_half_size, image.shape[1])\n",
    "    new_y2 = min(center_y + new_half_size, image.shape[0])\n",
    "    # Crop the image\n",
    "    cropped_img = image[int(new_y1):int(new_y2), int(new_x1):int(new_x2)]\n",
    "    return cropped_img\n",
    "\n",
    "def test_model(weights_path, image_dir, mask_dir, show=False):\n",
    "    \"\"\"\n",
    "    Test the trained YOLOv8 model on a set of images, crop the hand bounding boxes from both the images and the corresponding masks,\n",
    "    and save them to separate directories.\n",
    "    \"\"\"\n",
    "    image_dir = Path(image_dir)\n",
    "    mask_dir = Path(mask_dir)\n",
    "    cropped_images_dir = Path('Cropped_Images')\n",
    "    cropped_masks_dir = Path('Cropped_Masks')\n",
    "    model = YOLO(weights_path)\n",
    "    hand_detection_count = 0\n",
    "\n",
    "    for image_path in image_dir.iterdir():\n",
    "        image = cv2.imread(str(image_path))\n",
    "        results = model.predict(source=image, conf=0.3, iou=0.4)\n",
    "\n",
    "        # Extract the bounding boxes\n",
    "        detections = results[0].boxes.xyxy\n",
    "\n",
    "        # Check if there are any detections\n",
    "        if detections is not None and len(detections) > 0:\n",
    "            hand_detection_count += 1  # Increment the counter for each image with a detection\n",
    "            for i, box in enumerate(detections):\n",
    "                xyxy = box[:4].tolist()\n",
    "                cropped_image = crop_and_resize(image, xyxy)\n",
    "                cropped_mask = crop_mask_image(mask_dir, xyxy, image_path.name)\n",
    "\n",
    "                # Save the cropped image and mask\n",
    "                cropped_image_path = save_cropped_image(cropped_image, cropped_images_dir, image_path.name)\n",
    "                cropped_mask_path = save_cropped_image(cropped_mask, cropped_masks_dir, image_path.name)\n",
    "\n",
    "                '''if show:\n",
    "                    # Show the cropped image and mask side by side\n",
    "                    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "                    axs[0].imshow(cv2.cvtColor(cropped_image, cv2.COLOR_BGR2RGB))\n",
    "                    axs[0].set_title('Cropped Image')\n",
    "                    axs[1].imshow(cropped_mask, cmap='gray')\n",
    "                    axs[1].set_title('Cropped Mask')\n",
    "                    plt.show()'''\n",
    "\n",
    "        else:\n",
    "            print(f\"No results for image {image_path.name}\")\n",
    "    print(f\"Total number of images with detected hands: {hand_detection_count}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oouHO1b8KPly",
    "outputId": "20c5522e-48be-4bed-c1dd-7e09e28efb54"
   },
   "outputs": [],
   "source": [
    "weights_path = \"/content/drive/Shareddrives/Nikhil shared drive/COCO_Hand_Big2/weights/best.pt\"\n",
    "test_images_path = \"/content/data/Images\"\n",
    "mask_dir=\"/content/data/Masks\"\n",
    "test_model(weights_path, test_images_path,mask_dir, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qAv99sxLQGdM"
   },
   "outputs": [],
   "source": [
    "def smooth_mask(mask, blur_size=3):\n",
    "    \"\"\"\n",
    "    Apply Gaussian blur to the mask to smooth the edges.\n",
    "\n",
    "    Args:\n",
    "    - mask (numpy.ndarray): The mask image.\n",
    "    - blur_size (int): Size of the kernel to use for the Gaussian blur.\n",
    "\n",
    "    Returns:\n",
    "    - numpy.ndarray: The smoothed mask.\n",
    "    \"\"\"\n",
    "    return cv2.GaussianBlur(mask, (blur_size, blur_size), 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lJ-w0fMSCfii"
   },
   "outputs": [],
   "source": [
    "#To convert the masked images into labels txt file\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def mask_to_polygons(mask):\n",
    "    \"\"\"\n",
    "    Convert a mask image to a list of polygons.\n",
    "\n",
    "    Args:\n",
    "    - mask (numpy.ndarray): The mask image.\n",
    "\n",
    "    Returns:\n",
    "    - list: A list of polygons, each represented as a list of points (x, y).\n",
    "    \"\"\"\n",
    "    # Find contours in the mask\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    polygons = []\n",
    "    for contour in contours:\n",
    "        # Approximate the contour to a polygon\n",
    "        epsilon = 0.005 * cv2.arcLength(contour, True)\n",
    "        approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "        polygon = approx.ravel().tolist()\n",
    "        # Skip small or invalid contours\n",
    "        if len(polygon) >= 6:\n",
    "            polygons.append(polygon)\n",
    "    return polygons\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TDfIFFEpGmqL"
   },
   "outputs": [],
   "source": [
    "def save_polygons_to_txt(polygons, save_path):\n",
    "    \"\"\"\n",
    "    Save the polygon coordinates to a .txt file.\n",
    "\n",
    "    Args:\n",
    "    - polygons (list): A list of polygons.\n",
    "    - save_path (Path): The path to the .txt file where the coordinates will be saved.\n",
    "    \"\"\"\n",
    "    with open(save_path, 'w') as file:\n",
    "        for polygon in polygons:\n",
    "            coordinates = ','.join(map(str, polygon))\n",
    "            file.write(coordinates + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q73ZkVG1GEFO"
   },
   "outputs": [],
   "source": [
    "#Converting masks into labels\n",
    "def process_masks_to_polygons(masks_dir, labels_dir):\n",
    "    \"\"\"\n",
    "    Process all mask images in a directory, convert them to polygons, and save the results to .txt files.\n",
    "\n",
    "    Args:\n",
    "    - masks_dir (str): Directory where the mask images are stored.\n",
    "    - labels_dir (str): Directory where the .txt files will be saved.\n",
    "    \"\"\"\n",
    "    masks_dir = Path(masks_dir)\n",
    "    labels_dir = Path(labels_dir)\n",
    "    labels_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for mask_path in masks_dir.glob('*.jpg'):\n",
    "        mask = cv2.imread(str(mask_path), cv2.IMREAD_GRAYSCALE)\n",
    "        if mask is None:\n",
    "            continue\n",
    "        mask = smooth_mask(mask)\n",
    "        polygons = mask_to_polygons(mask)\n",
    "        txt_filename = mask_path.stem + '.txt'\n",
    "        save_path = labels_dir / txt_filename\n",
    "        save_polygons_to_txt(polygons, save_path)\n",
    "\n",
    "masks_dir = '/content/data/Cropped_Masks'\n",
    "labels_dir = '/content/data/Cropped_Labels'\n",
    "process_masks_to_polygons(masks_dir, labels_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "OOEKcJcMOqqh",
    "outputId": "cd94ba38-4425-4151-bba1-967d792642e2"
   },
   "outputs": [],
   "source": [
    "#Plotting the LABELS on Images and placing in folder\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Function to read polygons from a text file\n",
    "def read_polygons_from_file(file_path):\n",
    "    polygons = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            points = line.strip().split(',')\n",
    "            polygon = list(zip(map(int, points[::2]), map(int, points[1::2])))\n",
    "            polygons.append(polygon)\n",
    "    return polygons\n",
    "\n",
    "# Paths to the folders containing images and labels\n",
    "images_folder_path = '/content/drive/Shareddrives/Nikhil shared drive/GTEA Cropped Dataset 6.6k Images/Cropped_Images'  # Replace with your images folder path\n",
    "labels_folder_path = '/content/data/Cropped_Labels'  # Replace with your labels folder path\n",
    "output_folder_path = '/content/data/Cropped_LabelsonImages'\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "if not os.path.exists(output_folder_path):\n",
    "    os.makedirs(output_folder_path)\n",
    "\n",
    "# Get a list of image files and corresponding label files\n",
    "image_files = [f for f in os.listdir(images_folder_path) if f.endswith('.jpg')]\n",
    "label_files = [f.replace('.jpg', '.txt') for f in image_files]\n",
    "\n",
    "# Loop through the image and label files\n",
    "for image_file, label_file in zip(image_files, label_files):\n",
    "    image_path = os.path.join(images_folder_path, image_file)\n",
    "    label_path = os.path.join(labels_folder_path, label_file)\n",
    "    output_image_path = os.path.join(output_folder_path, image_file)\n",
    "    # Read polygons from the text file\n",
    "    polygons = read_polygons_from_file(label_path)\n",
    "\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Check if the image was successfully loaded\n",
    "    if image is None:\n",
    "        print(f\"Error: Image {image_file} not found.\")\n",
    "        continue\n",
    "\n",
    "    # Convert image to RGB (OpenCV uses BGR by default)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Draw the polygons on the image\n",
    "    for polygon in polygons:\n",
    "        pts = np.array(polygon, np.int32)\n",
    "        pts = pts.reshape((-1, 1, 2))\n",
    "        cv2.polylines(image, [pts], isClosed=True, color=(0, 255, 0), thickness=2)\n",
    "\n",
    "    # Save the image with polygons\n",
    "    cv2.imwrite(output_image_path, cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "print(\"Processing complete. Images with labeled polygons are saved in 'Cropped_LabelsonImages' folder.\")\n",
    "\n",
    "'''# Display the image with polygons\n",
    "    plt.imshow(image)\n",
    "    plt.title(f'Polygons on {image_file}')\n",
    "    plt.axis('off')  # Hide the axis\n",
    "    plt.show()'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "f1Vbr7cx3f1r",
    "outputId": "df5367bd-cce5-410f-bc00-6fa9baadc5af"
   },
   "outputs": [],
   "source": [
    "#To download folder into local system\n",
    "import os\n",
    "from google.colab import files\n",
    "from zipfile import ZipFile\n",
    "\n",
    "def zip_folder(folder_path, zip_path):\n",
    "    \"\"\"\n",
    "    Zip the contents of an entire folder (with that folder included in the archive).\n",
    "    Existing files with the same name will be overwritten.\n",
    "\n",
    "    Args:\n",
    "    - folder_path (str): The path to the folder to zip.\n",
    "    - zip_path (str): The complete target path for the created zip file.\n",
    "    \"\"\"\n",
    "    with ZipFile(zip_path, 'w') as zipf:\n",
    "        for root, dirs, files in os.walk(folder_path):\n",
    "            for file in files:\n",
    "                # Create a relative path for files to keep the directory structure\n",
    "                relative_path = os.path.relpath(os.path.join(root, file), os.path.join(folder_path, '..'))\n",
    "                zipf.write(os.path.join(root, file), relative_path)\n",
    "\n",
    "def download_folder(folder_path):\n",
    "    \"\"\"\n",
    "    Compress and download the given folder.\n",
    "\n",
    "    Args:\n",
    "    - folder_path (str): The path to the folder to download.\n",
    "    \"\"\"\n",
    "    zip_path = f\"{folder_path}.zip\"\n",
    "    zip_folder(folder_path, zip_path)\n",
    "    files.download(zip_path)\n",
    "\n",
    "# Example usage:\n",
    "folder_to_download = '/content/data/Cropped_Labels'  # Change this to the path of the folder you want to download\n",
    "download_folder(folder_to_download)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XIce4WrTcC1G",
    "outputId": "fe77cf78-470e-4253-c189-17f565be0c93"
   },
   "outputs": [],
   "source": [
    "#to count number of images in a directory\n",
    "import os\n",
    "\n",
    "def count_images_in_folder(folder_path):\n",
    "    # List all files in the folder\n",
    "    files = os.listdir(folder_path)\n",
    "    # Count files with image extensions (assuming common image formats)\n",
    "    image_count = sum(1 for file in files if file.lower().endswith(('.png', '.jpg', '.jpeg', '.txt', '.gif', '.tiff')))\n",
    "    return image_count\n",
    "\n",
    "folder_path = '/content/data/Cropped_LabelsonImages'  # Replace with your folder path\n",
    "print(f\"Number of images in the folder: {count_images_in_folder(folder_path)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UmIjdPc5AY98",
    "outputId": "428044ae-be9e-42ce-f107-f5c5b7fbfab5"
   },
   "outputs": [],
   "source": [
    "#renaming files in folder\n",
    "import os\n",
    "\n",
    "# Define the directory where your images are located\n",
    "directory = \"/content/drive/Shareddrives/Nikhil shared drive/Cropped_Masks\"  # Adjust the path to your specific directory\n",
    "\n",
    "# Iterate over all files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.startswith(\"Mask_\"):  # Check if the filename starts with \"Image_\"\n",
    "        # Construct the old file path\n",
    "        old_file = os.path.join(directory, filename)\n",
    "\n",
    "        # Construct the new file path with \"Image_\" removed from the filename\n",
    "        new_file = os.path.join(directory, filename.replace(\"Mask_\", \"\"))\n",
    "\n",
    "        # Rename the file\n",
    "        os.rename(old_file, new_file)\n",
    "        print(f'Renamed: {old_file} to {new_file}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pf_ALQiHGFMo"
   },
   "outputs": [],
   "source": [
    "#To clear entire directory contents\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "def clear_directory_contents(dir_path):\n",
    "    \"\"\"\n",
    "    Remove all files and subdirectories in the specified directory.\n",
    "\n",
    "    Args:\n",
    "    - dir_path (str): The path to the directory to clear.\n",
    "    \"\"\"\n",
    "    for filename in os.listdir(dir_path):\n",
    "        file_path = os.path.join(dir_path, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print(f'Failed to delete {file_path}. Reason: {e}')\n",
    "\n",
    "# Example usage:\n",
    "directory_to_clear = '/content/drive/Shareddrives/Nikhil shared drive/Cropped_Masks'  # Replace with your directory path\n",
    "clear_directory_contents(directory_to_clear)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3u5dtQKM5d8x"
   },
   "outputs": [],
   "source": [
    "#To upload folder from colab to drive\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "def upload_file_to_drive(source, destination):\n",
    "    source_path = Path(source)\n",
    "    destination_path = Path(destination)\n",
    "\n",
    "    # Check if the source is a file or directory\n",
    "    if source_path.is_file():\n",
    "        # Copy the file\n",
    "        shutil.copy2(source, destination)\n",
    "    elif source_path.is_dir():\n",
    "        # Copy the directory\n",
    "        destination_path = destination_path / source_path.name\n",
    "        shutil.copytree(source, destination_path)\n",
    "    else:\n",
    "        print(f\"The source {source} is neither a file nor a directory.\")\n",
    "\n",
    "\n",
    "upload_file_to_drive('/content/Cropped_LabelsonImages', '/content/drive/MyDrive')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
